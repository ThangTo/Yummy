"""
AI Service - FastAPI Microservice
X·ª≠ l√Ω ·∫£nh m√≥n ƒÉn b·∫±ng 3 models song song (InceptionV3, ResNet152V2, VGG19)
"""

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
from typing import Dict, List
import uvicorn
import numpy as np

from services.model_service import ModelService
from services.prediction_service import PredictionService
from utils.image_processor import ImageProcessor

app = FastAPI(
    title="Yummy AI Service",
    description="AI Microservice for Vietnamese Food Recognition",
    version="1.0.0",
)

# CORS middleware ƒë·ªÉ cho ph√©p Node.js backend g·ªçi API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Trong production n√™n gi·ªõi h·∫°n origin
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kh·ªüi t·∫°o services
model_service = ModelService()
prediction_service = PredictionService()
image_processor = ImageProcessor()


@app.on_event("startup")
async def load_models():
    """
    Load t·∫•t c·∫£ 3 models v√†o RAM khi server kh·ªüi ƒë·ªông.
    ƒê√¢y l√† k·ªπ thu·∫≠t t·ªëi ∆∞u Performance quan tr·ªçng nh·∫•t - lo·∫°i b·ªè Cold Start.
    """
    print("üöÄ System: ƒêang n·∫°p 3 Models v√†o b·ªô nh·ªõ...")
    try:
        await model_service.load_all_models()
        print(f"‚úÖ System: ƒê√£ load {len(model_service.models)} models. S·∫µn s√†ng ph·ª•c v·ª•!")
    except Exception as e:
        print(f"‚ùå Error loading models: {e}")
        import traceback
        traceback.print_exc()
        raise


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "running",
        "service": "Yummy AI Service",
        "models_loaded": model_service.models_loaded(),
    }


@app.get("/health")
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "models": model_service.get_models_status(),
    }


@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """
    Nh·∫≠n ·∫£nh m√≥n ƒÉn v√† ch·∫°y 3 models song song ƒë·ªÉ d·ª± ƒëo√°n.
    
    Args:
        file: ·∫¢nh m√≥n ƒÉn (multipart/form-data)
    
    Returns:
        {
            "best_match": "T√™n m√≥n ƒÉn",
            "confidence": 0.98,
            "model_details": {
                "inception_v3": {"prediction": "Pho", "confidence": 0.95},
                "resnet152_v2": {"prediction": "Pho", "confidence": 0.92},
                "vgg19": {"prediction": "Pho", "confidence": 0.88},
            },
            "voting_result": {...}
        }
    """
    try:
        # 1. ƒê·ªçc ·∫£nh t·ª´ RAM (kh√¥ng ghi ra ƒëƒ©a ƒë·ªÉ t·ªëi ∆∞u I/O)
        image_bytes = await file.read()
        image = Image.open(io.BytesIO(image_bytes))
        
        # 2. Ch·∫°y 3 models song song (parallel inference)
        # Image s·∫Ω ƒë∆∞·ª£c preprocess ri√™ng cho t·ª´ng model trong prediction_service
        predictions = await prediction_service.predict_all_models(
            image,  # Truy·ªÅn PIL Image g·ªëc
            model_service.models,
            image_processor
        )
        
        # 4. Voting mechanism ƒë·ªÉ ch·ªçn k·∫øt qu·∫£ cu·ªëi c√πng
        voting_result = prediction_service.vote(predictions)
        
        # 5. Format response ƒë·ªÉ match v·ªõi backend expectation
        model_details_formatted = {}
        for model_name, result in predictions.items():
            model_details_formatted[model_name] = {
                "prediction": result.get("prediction", "Unknown"),
                "confidence": result.get("confidence", 0.0)
            }
        
        return {
            "best_match": voting_result["prediction"],
            "confidence": voting_result["confidence"],
            "model_details": model_details_formatted,
            "voting_result": voting_result,
        }
        
    except Exception as e:
        print(f"‚ùå Error in predict: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)

